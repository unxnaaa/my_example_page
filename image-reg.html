<!DOCTYPE html>
<html lang="en">
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <meta http-equiv="x-ua-compatible" content="ie=edge" />
    <title></title>
    <head>

    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.2/css/bootstrap.min.css" integrity="sha384-Smlep5jCw/wG7hdkwQ/Z5nLIefveQRIY9nfy6xoR1uRYBtpZgI6339F5dgvm/e9B" crossorigin="anonymous">
  
    <body>
        <style>
           .center-page {
                position: absolute;
                top: 50%;
                left: 50%;
                -moz-transform: translateX(-50%) translateY(-50%);
                -webkit-transform: translateX(-50%) translateY(-50%);
                transform: translateX(-50%) translateY(-50%);
            }
            .profile_image {
  
            width: 100px;
            height: 100px;
            display: inline-block;
            margin: 0px auto;
            padding:10px;
            border-radius: 100px;
            /*float: left;*/
            /*background: red;*/
            z-index: 1000;
            overflow: hidden;
        
        }
        </style>
        <div class="container text-center" style="width:100%; height:100vh; background-color:white">
            <div class="container center-page" style="background-color:white">
                    <h2>Your Model Name (Image)</h2>
                    <h6>Describe your model.... This model is trained to recognize more than 17,771 popular 
                        landmarks from Asia. The model is mobile-friendly and can run on-device.
                        This model was trained on Google Landmarks Dataset V2</h6>
                    <div>Teachable Machine Image Model</div>
                    <button type="button" type="button" class="btn btn-primary" onclick="init()">Try it out!!</button>
                    
                    <br>
                    <div id="webcam-container"></div>
                    <div id="label-container"></div>
                    <br>
                    <h2>Student</h2>
                    <img id="my-profile-img" src="https://firebasestorage.googleapis.com/v0/b/iamhere2-c06af.appspot.com/o/kunAppResource%2Fic_account_circle_black_24dp_2x.png?alt=media&token=c14849e9-7fff-4531-a99a-ac76b7a405d1" class="profile_image"
                    alt="avatar image">
                    <p>.......</p>

        </div>
           

        </div>
         <!-- Bootstrap JS -->
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.2/js/bootstrap.min.js" integrity="sha384-o+RDsa0aLu++PJvFqy8fFScvbHFLtbvScb8AjopnFD+iEQ7wo/CG0xlczd+2O/em" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8/dist/teachablemachine-image.min.js"></script>
        <script type="text/javascript">
            // More API functions here:
            // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image

            // the link to your model provided by Teachable Machine export panel
            const URL = "https://teachablemachine.withgoogle.com/models/yPvhj88RK/";

            let model, webcam, labelContainer, maxPredictions;
            let is_click = false
            // Load the image model and setup the webcam
            async function init() {
                if(is_click == true){
                    return
                }
                is_click = true;
                const modelURL = URL + "model.json";
                const metadataURL = URL + "metadata.json";
                // load the model and metadata
                // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
                // or files from your local hard drive
                // Note: the pose library adds "tmImage" object to your window (window.tmImage)
                model = await tmImage.load(modelURL, metadataURL);
                maxPredictions = model.getTotalClasses();

                // Convenience function to setup a webcam
                const flip = true; // whether to flip the webcam
                webcam = new tmImage.Webcam(200, 200, flip); // width, height, flip
                await webcam.setup(); // request access to the webcam
                await webcam.play();
                window.requestAnimationFrame(loop);

                // append elements to the DOM
                document.getElementById("webcam-container").appendChild(webcam.canvas);
                labelContainer = document.getElementById("label-container");
                for (let i = 0; i < maxPredictions; i++) { // and class labels
                    labelContainer.appendChild(document.createElement("div"));
                }
            }

            async function loop() {
                webcam.update(); // update the webcam frame
                await predict();
                window.requestAnimationFrame(loop);
            }

            // run the webcam image through the image model
            async function predict() {
                // predict can take in an image, video or canvas html element
                const prediction = await model.predict(webcam.canvas);
                for (let i = 0; i < maxPredictions; i++) {
                    const classPrediction =
                        prediction[i].className + ": " + prediction[i].probability.toFixed(2);
                    labelContainer.childNodes[i].innerHTML = classPrediction;
                }
            }
            // stop camera //
            async function stop(p) {
                console.log('stop')
                await webcam.play();
                
            }
        </script>
</body>
</html>
